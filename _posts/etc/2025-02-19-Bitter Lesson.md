---
title: "The Bitter Lesson by Richard Sutton"
last_modified_at: 2025-02-19
categories:
  - etc
tags:
excerpt: "The Bitter Lesson by Richard Sutton"
use_math: true
classes: wide
---

[[원문](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)]

쓰라린 교훈
리치 서튼 (Rich Sutton)
2019년 3월 13일

지난 70년간의 인공지능(AI) 연구에서 얻을 수 있는 가장 큰 교훈은, 계산 자원을 활용하는 일반적인 방법이 궁극적으로 가장 효과적이라는 점이며, 그것도 압도적인 차이로 그렇다는 것이다. 이러한 현상의 근본적인 이유는 무어의 법칙(Moore's Law), 혹은 더 일반적으로 말하면, 연산 단위당 비용이 지속적으로 기하급수적으로 감소한다는 사실 때문이다. 대부분의 AI 연구는 주어진 계산 자원이 고정되어 있다는 전제하에 수행되었다. 이런 환경에서는 인간의 지식을 활용하는 것이 성능을 향상시키는 거의 유일한 방법 중 하나처럼 보인다. 그러나 연구 프로젝트보다 약간 더 긴 시간 동안을 놓고 보면, 결국 훨씬 더 방대한 계산 자원이 사용 가능해진다.

연구자들은 단기적으로 의미 있는 성과를 내기 위해 인간의 도메인 지식을 활용하려고 하지만, 장기적으로 보면 오직 계산 자원의 활용만이 중요하다. 물론 두 접근 방식이 반드시 상충하는 것은 아니지만, 현실적으로는 대개 그렇게 된다. 한 가지 접근법에 시간을 쏟으면 다른 방법에 시간을 쓰지 못하게 된다. 또한, 연구자들은 자신이 투자한 방법에 심리적으로 집착하게 된다. 인간의 지식을 기반으로 하는 접근법은 종종 알고리즘을 복잡하게 만들어, 대규모 연산을 활용하는 일반적인 방법과는 조화를 이루기 어렵게 만든다.

AI 연구자들이 이러한 '쓰라린 교훈(The Bitter Lesson)'을 뒤늦게 깨달은 사례는 많으며, 그중 대표적인 몇 가지를 살펴보는 것은 유익할 것이다.

체스 인공지능에서의 교훈
1997년, 체스 세계 챔피언 카스파로프(Garry Kasparov)를 무찌른 체스 인공지능은 대규모의 깊은 탐색(search)에 기반을 두고 있었다. 당시 컴퓨터 체스를 연구하던 많은 연구자들은 이에 대해 실망감을 감추지 못했다. 그들은 체스의 특수한 구조에 대한 인간의 이해를 활용하는 방법을 개발해왔는데, 단순한 탐색 기반 접근법이 특수 하드웨어와 소프트웨어의 도움을 받아 훨씬 더 효과적이라는 사실이 드러나자 낙담했다.

이들은 "브루트 포스(brute force) 방식의 탐색이 이번에는 우세했지만, 이는 일반적인 전략이 아니며, 무엇보다 인간이 체스를 두는 방식과 다르다"고 주장했다. 연구자들은 인간의 지식을 활용하는 방법이 우위를 점하기를 바랐지만, 결국 그러지 못했다.

바둑 인공지능에서의 교훈
체스와 비슷한 연구 패턴이 바둑에서도 나타났지만, 20년 정도 더 지연되었다. 초기 연구에서는 탐색을 피하기 위해 인간의 지식이나 바둑의 특수한 특징을 활용하려는 시도가 많았다. 그러나 이러한 노력들은 결국 무의미해졌거나 오히려 방해 요소로 작용했다. 탐색을 효과적으로 확장하여 적용할 수 있게 되자, 모든 기존 방법이 무력해졌다.

자기 대국(self-play)을 통한 학습 역시 중요한 역할을 했다. 자기 대국을 통해 가치 함수(value function)를 학습하는 방식은 체스, 바둑뿐만 아니라 다른 게임에서도 널리 활용되었다. (다만, 1997년 체스 챔피언을 이긴 프로그램에서는 학습이 큰 역할을 하지 않았다.)

자기 대국을 통한 학습과 학습 일반은 탐색과 마찬가지로 대규모 계산 자원을 활용하는 방법 중 하나이다. AI 연구에서 방대한 계산을 효과적으로 활용하는 두 가지 핵심 기술은 탐색(search) 과 학습(learning) 이다. 바둑에서도 체스와 마찬가지로, 초기 연구들은 인간의 이해를 활용하여 탐색을 줄이는 데 집중했지만, 결국 탐색과 학습을 적극적으로 받아들였을 때 훨씬 더 큰 성과를 거둘 수 있었다.

음성 인식에서의 교훈
1970년대, DARPA가 주최한 초기 음성 인식 대회에서는 다양한 접근법이 경쟁했다. 참가한 연구팀들 중 일부는 단어, 음소(phoneme), 인간의 성대 구조 등에 대한 지식을 활용하는 특수한 방법을 개발했다. 반면, 다른 연구팀들은 더 많은 연산을 수행하는 통계적 접근법을 시도했다. 예를 들면, 은닉 마르코프 모델(Hidden Markov Model, HMM) 기반의 방법이 있었다.

결과적으로, 통계적 방법이 인간의 지식을 기반으로 한 방법을 압도했다. 이는 자연어 처리(NLP) 전체의 연구 방향을 변화시키는 계기가 되었으며, 수십 년에 걸쳐 점진적으로 통계와 계산 중심의 방법이 지배적인 접근법으로 자리 잡게 되었다.

최근의 딥러닝 기반 음성 인식 기술은 이러한 방향을 더욱 극단적으로 발전시켰다. 딥러닝 기법은 인간의 지식을 거의 활용하지 않으며, 대신 방대한 연산과 거대한 데이터셋을 활용하여 이전보다 훨씬 더 우수한 성능을 발휘한다.

과거 연구자들은 시스템이 자신들의 사고방식과 유사한 방식으로 작동하기를 원했다. 그래서 연구자들은 인간의 지식을 시스템에 내장하려고 했으나, 이는 결국 비효율적이고 연구자들의 시간을 낭비하는 결과를 초래했다. 시간이 지나면서 무어의 법칙에 따라 방대한 계산 자원이 사용 가능해졌고, 이를 효과적으로 활용하는 방법이 등장하자 기존의 접근법들은 모두 도태되었다.

컴퓨터 비전에서의 교훈
비슷한 패턴이 컴퓨터 비전에서도 나타났다. 초기 연구자들은 시각 정보를 처리하는 방법을 엣지(edge) 검출, 일반화된 실린더(generalized cylinders), 또는 SIFT(feature-based) 방식으로 접근하려 했다. 그러나 오늘날 이러한 방법들은 모두 버려졌다.

현대의 딥러닝 기반 신경망은 단순히 컨볼루션(convolution)과 특정한 불변성(invariance) 개념만을 사용하지만, 기존의 복잡한 방법보다 훨씬 더 우수한 성능을 보인다.

쓰라린 교훈
이것이 바로 AI 연구가 배워야 할 쓰라린 교훈(The Bitter Lesson) 이다. 하지만 우리는 여전히 이 교훈을 완전히 습득하지 못했다. 여전히 같은 실수를 반복하고 있다.

이러한 실수들이 반복되는 이유를 이해해야만 효과적으로 이를 극복할 수 있다. 연구자들은 인간이 사고하는 방식을 시스템에 내장하려는 경향이 있다. 이는 단기적으로는 유용하고 연구자 개인에게는 성취감을 줄 수 있지만, 장기적으로 보면 발전을 저해하는 요인이 된다.

쓰라린 교훈에서 얻어야 할 첫 번째 교훈은, 일반적인 방법(general-purpose methods)의 강력함 이다. 시간이 지나면서 사용할 수 있는 계산 자원이 급증하기 때문에, 이러한 환경에서도 지속적으로 확장 가능한 방법이 필요하다. 현재까지 이런 특성을 가진 방법으로는 탐색(search) 과 학습(learning) 이 있다.

두 번째 교훈은, 인간의 사고 내용은 너무나 복잡하며 단순한 방식으로 이를 표현하려는 시도는 실패할 수밖에 없다 는 점이다. 우리는 공간, 객체, 다중 에이전트, 대칭성 등에 대해 단순화된 개념을 적용하려 하지만, 실제 세계는 근본적으로 복잡하며 이를 직접 내장하는 것은 바람직하지 않다. 대신, 이러한 복잡성을 찾아내고 포착할 수 있는 메타 방법(meta-methods) 을 구축해야 한다.

궁극적으로, 우리는 AI가 인간이 발견한 지식을 내장하는 것이 아니라, 우리처럼 스스로 발견할 수 있도록 만들어야 한다.