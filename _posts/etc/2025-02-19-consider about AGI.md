---
title: "Dear Elon Musk, here are five things you might want to consider about AGI by Gary Marcus"
last_modified_at: 2025-02-19
categories:
  - etc
tags:
excerpt: "Consider about AGI by Gary Marcus"
use_math: true
classes: wide
---

[[원문](https://garymarcus.substack.com/p/dear-elon-musk-here-are-five-things)]

### 친애하는 일론(Elon)에게,  

어제 당신은 2029년까지 **AGI(인공지능 일반지능, Artificial General Intelligence)** 가 등장할 것으로 예상한다고 발표했습니다. (AGI는 체스나 단백질 접기 같은 특정 작업을 수행하는 **좁은 AI(Narrow AI)** 와는 대조되는 개념입니다.)  

이에 대해 저는 당신과 내기를 걸겠다고 했지만, 아직 아무런 답을 받지 못했습니다. 산타페 연구소의 AI 전문가 **멜라니 미첼(Melanie Mitchell)** 은 우리가 **longbets.org**에서 공식적으로 내기를 할 것을 제안했지만, 이에 대한 응답도 없었습니다. 그러나 일론, 저는 언제든지 응할 준비가 되어 있습니다.  

그렇지만 당신의 돈을 가져가기 전에, 먼저 대화를 나눠보고 싶습니다. 다음은 당신이 고려해야 할 다섯 가지 사항입니다.  

---

### 1. 당신의 예측 정확도는 그다지 신뢰할 만하지 않습니다.  

당신을 오랫동안 지켜봐 왔는데, **당신이 특정 기술의 발전 시기를 정확하게 예측한 적이 거의 없다는 점** 을 알고 있습니다.  

예를 들어, 2015년에 **완전한 자율주행 자동차** 가 2년 안에 가능할 것이라고 말했지만, 이후 거의 매년 비슷한 예측을 해왔을 뿐, **아직도 실현되지 않았습니다.**  

---

### 2. **극단적 사례(Edge Cases)의 어려움을 과소평가하고 있습니다.**  

AI 문제는 생각보다 훨씬 어렵습니다. 왜냐하면 우리가 자주 접하는 상황에서는 AI가 잘 작동하지만, 드문 사건(극단적 사례)에서는 데이터가 부족하여 매우 취약하기 때문입니다. 이를 **"롱테일(long tail) 문제"** 라고 합니다.  

**인간은 불완전한 정보로도 추론할 수 있지만, AI는 단순한 데이터 패턴을 학습하는 방식이라 극단적 상황에서 쉽게 무너집니다.**  

저는 2016년 **Edge.org** 인터뷰에서 이에 대해 경고한 적이 있습니다.  

> **"AI 연구에 대한 엄청난 과대 광고와 투자에도 불구하고, 저는 이 분야가 잘못된 방향으로 가고 있다고 느낍니다. 지금의 AI는 딥러닝과 빅데이터에 치우쳐 있고, 이 방법들은 근본적인 AI 문제(언어 이해, 논리적 추론 등)를 해결하는 데 별로 기여하지 못합니다."**  

자율주행 자동차의 예를 들어보겠습니다.  

> **"맑은 날, 팔로알토(Palo Alto) 같은 환경에서는 자율주행차가 아주 훌륭하게 작동합니다. 그러나 눈이나 비가 내리는 곳에서는 어려움을 겪습니다. 2015년 말, 구글 자율주행차 연구소에서는 드디어 자동차가 '나뭇잎'을 인식할 수 있게 되었다는 것을 큰 성과로 발표했습니다. 하지만 현실에는 AI가 해결해야 할 수많은 예외적인 상황이 존재합니다."**  

**테슬라의 현재 자율주행 시스템도 마찬가지입니다.** 여전히 **딥러닝 기반의 "검색(hash-table-like lookup)" 방식** 을 사용하고 있기 때문에, 예상치 못한 상황에 매우 취약합니다.  

최근에는 "소환(summon)" 기능을 사용하던 **테슬라 모델 Y가 공항에 주차된 300만 달러짜리 비행기에 충돌하는 사건** 이 있었습니다.  

**이러한 예측 불가능한 상황들이 AI 발전을 지연시키고 있으며, 현재의 기술로는 해결되지 않고 있습니다.**  

당신이 TED에서 크리스 앤더슨(Chris Anderson)에게 **"올해나 내년에 레벨 5 자율주행을 출시하겠다"** 고 말했지만, **저는 100% 불가능하다고 장담할 수 있습니다.**  

**극단적 사례 문제를 해결하려면 새로운 패러다임이 필요하며, 단순한 딥러닝의 확장만으로는 불가능합니다.**  

---

### 3. **AGI는 엄청나게 광범위한 문제입니다.**  

**지능(intelligence)은 단일한 개념이 아닙니다.**  

인지과학자 **Chaz Firestone** 과 **Brian Scholl** 의 말을 인용하겠습니다.  

> **"마음이 작동하는 방식은 하나가 아니다. 마음은 여러 부분으로 이루어져 있으며, 각각 다르게 작동한다. 색을 인식하는 방식과 휴가를 계획하는 방식은 다르며, 문장을 이해하는 방식, 팔다리를 움직이는 방식, 사실을 기억하는 방식, 감정을 느끼는 방식도 모두 다르다."**  

현대 AI는 **사물을 인식하는 데는 뛰어나지만**,  
- **계획(Planning)**  
- **읽기(Reading)**  
- **언어 이해(Language Comprehension)**  

같은 문제에서는 여전히 초보적인 수준에 머물러 있습니다.  

저는 2018년 **"딥러닝: 비판적 평가(Deep Learning: A Critical Appraisal)"** 라는 글에서 이를 다음과 같이 요약했습니다.  

> **"딥러닝은 만능 해결책이 아니다. 우리는 딥러닝을 전지전능한 도구가 아니라, 단순한 전동드라이버 정도로 여겨야 한다. 그러나 우리는 여전히 망치, 렌치, 플라이어, 심지어 논리 프로브와 오실로스코프 같은 다양한 도구가 필요하다."**  

---

### 4. **우리는 아직 복잡한 인지 시스템을 만들 방법조차 모릅니다.**  

AGI는 엄청나게 복잡한 시스템이므로, 단순한 패치(patch) 추가로 해결할 수 없습니다.  

지금의 딥러닝 시스템은 **블랙박스(black box)** 입니다.  

> **"딥러닝 시스템을 디버깅하는 것은 악몽과도 같습니다. 기존의 소프트웨어 개발처럼 논리적으로 버그를 추적할 수 없으며, 단순히 데이터를 더 추가하고 모델을 다시 학습시키는 방식이 전부입니다."**  

페이스북이 최근 공개한 **대형 언어 모델(OPT) 학습 과정** 을 보면, 실질적으로 연구자들이 **엄청난 시행착오(trial-and-error)** 를 겪고 있음을 알 수 있습니다.  

**현재 AI 연구는 과학보다 연금술(Alchemy)에 가깝습니다.**  

---

### 5. **내기를 하려면 AGI의 기준을 명확히 해야 합니다.**  

AGI는 너무 모호한 개념이므로, 우리는 구체적인 기준을 정해야 합니다.  

제 기준은 다음과 같습니다.  

**2029년까지 AI는 다음 다섯 가지를 해결하지 못할 것입니다.**  

1. **영화를 보고 줄거리를 정확히 설명하지 못할 것이다.**  
2. **소설을 읽고 줄거리, 인물 관계, 동기 등을 완벽하게 이해하지 못할 것이다.**  
3. **임의의 가정에서 요리할 수 있는 능력을 갖추지 못할 것이다.**  
4. **10,000줄 이상의 코드를 자연어로 작성하고, 버그 없이 구현하지 못할 것이다.**  
5. **수학 논문을 완전히 이해하고 기호 논리로 변환하는 능력을 갖추지 못할 것이다.**  

이 중 **단일 시스템이 3개 이상 해결하면 당신이 승리** 입니다.  

그렇지 않으면, 제가 이깁니다.  

---

### 결론: **$100,000 내기, 받아들일 건가요?**  

당신이 동의한다면, 내기의 세부 조건을 논의하기 위해 연락 주시기 바랍니다.  

**진심을 담아,**  
**게리 마커스 (Gary Marcus)**